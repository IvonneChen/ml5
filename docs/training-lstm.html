<html lang="en"><head><meta charset="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>Training a LSTM · ML5.js</title><meta name="viewport" content="width=device-width"/><meta name="generator" content="Docusaurus"/><meta property="og:title" content="Training a LSTM · ML5.js"/><meta property="og:type" content="website"/><meta property="og:url" content="https://itpnyu.github.io/ml5-js/index.html"/><meta property="og:description" content="Multi-layer Recurrent Neural Networks (LSTM, RNN) for character-level language models in Python using Tensorflow and modified to work with [deeplearn.js](https://github.com/PAIR-code/deeplearnjs) and p5ML.js"/><link rel="shortcut icon" href="/ml5-js/img/favicon.png"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/solarized-dark.min.css"/><script type="text/javascript" src="https://rawgit.com/ITPNYU/ml5-js/master/dist/ml5.min.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/0.5.16/p5.min.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/0.5.16/addons/p5.dom.min.js"></script><link rel="stylesheet" href="/ml5-js/css/main.css"/></head><body class="sideNavVisible"><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/ml5-js/"><h2 class="headerTitle">ML5.js</h2></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li><a href="/ml5-js/docs/getting-started.html" target="_self">API</a></li><li><a href="/ml5-js/docs/simple-image-classification-example.html" target="_self">Examples</a></li><li><a href="/ml5-js/en/experiments.html" target="_self">Experiments</a></li><li><a href="/ml5-js/docs/glossary-statistics.html" target="_self">Learn</a></li><li><a href="https://github.com/ITPNYU/ml5-js" target="_self">Code</a></li></ul></nav></div></header></div></div><div class="navPusher"><div class="docMainWrapper wrapper"><div class="container docsNavContainer" id="docsNav"><nav class="toc"><div class="toggleNav"><section class="navWrapper wrapper"><div class="navBreadcrumb wrapper"><div class="navToggle" id="navToggler"><i></i></div><h2><i>›</i><span>Training Models</span></h2></div><div class="navGroups"><div class="navGroup navGroupActive"><h3>Documentation</h3><ul><li class="navListItem"><a class="navItem" href="/ml5-js/docs/getting-started.html">Getting Started</a></li><li class="navListItem"><a class="navItem" href="/ml5-js/docs/imagenet.html">Imagenet</a></li><li class="navListItem"><a class="navItem" href="/ml5-js/docs/knnImage.html">KNN Image Classifier</a></li><li class="navListItem"><a class="navItem" href="/ml5-js/docs/lstm.html">LSTM</a></li><li class="navListItem"><a class="navItem" href="/ml5-js/docs/neural-network.html">Neural Network</a></li><li class="navListItem"><a class="navItem" href="/ml5-js/docs/transform-net.html">Transform Net</a></li><li class="navListItem"><a class="navItem" href="/ml5-js/docs/word2vec.html">Word2Vec</a></li></ul></div><div class="navGroup navGroupActive"><h3>Examples</h3><ul><li class="navListItem"><a class="navItem" href="/ml5-js/docs/simple-image-classification-example.html">Simple Image Classification</a></li><li class="navListItem"><a class="navItem" href="/ml5-js/docs/video-classification-example.html">Video Classification</a></li><li class="navListItem"><a class="navItem" href="/ml5-js/docs/knn-image-example.html">KNN Image Classification</a></li><li class="navListItem"><a class="navItem" href="/ml5-js/docs/lstm-simple-example.html">Simple LSTM</a></li><li class="navListItem"><a class="navItem" href="/ml5-js/docs/lstm-interactive-example.html">Interactive LSTM</a></li><li class="navListItem"><a class="navItem" href="/ml5-js/docs/neural-network-example.html">Neural Network</a></li><li class="navListItem"><a class="navItem" href="/ml5-js/docs/transform-net-example.html">Fast Style Transfer</a></li><li class="navListItem"><a class="navItem" href="/ml5-js/docs/word2vec-example.html">Word2Vec</a></li></ul></div><div class="navGroup navGroupActive"><h3>Training Models</h3><ul><li class="navListItem"><a class="navItem" href="/ml5-js/docs/training-setup.html">Python Setup</a></li><li class="navListItem navListItemActive"><a class="navItem navItemActive" href="/ml5-js/docs/training-lstm.html">Training a LSTM</a></li></ul></div></div></section></div><script>
          var toggler = document.getElementById('navToggler');
          var nav = document.getElementById('docsNav');
          toggler.onclick = function() {
            nav.classList.toggle('docsSliderActive');
          };
        </script></nav></div><div class="container mainContainer"><div class="wrapper"><div class="post"><header class="postHeader"><h1>Training a LSTM</h1></header><article><div><span><p>Multi-layer Recurrent Neural Networks (LSTM, RNN) for character-level language models in Python using Tensorflow and modified to work with <a href="https://github.com/PAIR-code/deeplearnjs">deeplearn.js</a> and p5ML.js</p>
<p>Based on <a href="https://github.com/sherjilozair/char-rnn-tensorflow">char-rnn-tensorflow</a>.</p>
<h2><a class="anchor" aria-hidden="true" name="requirements"></a><a href="#requirements" aria-hidden="true" class="hash-link" ><svg aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Requirements</h2>
<p>Set up a python environment with tensorflow installed. <a href="../">More detailed instructions here</a></p>
<h2><a class="anchor" aria-hidden="true" name="usage"></a><a href="#usage" aria-hidden="true" class="hash-link" ><svg aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Usage</h2>
<h3><a class="anchor" aria-hidden="true" name="1-train"></a><a href="#1-train" aria-hidden="true" class="hash-link" ><svg aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>1) Train</h3>
<p>Inside the <code>/data</code> folder, create a new folder with the name of your data. Inside that folder should be one file called <code>input.txt</code>
(A quick tip to concatenate many small disparate <code>.txt</code> files into one large training file: <code>ls *.txt | xargs -L 1 cat &gt;&gt; input.txt</code>)
Then run:</p>
<pre><code class="hljs css bash">python train.py --data_dir=./data/my_own_data/
</code></pre>
<p>You can specify the hyperparameters:</p>
<pre><code class="hljs css bash">python train.py --data_dir=./data/my_own_data/ --rnn_size 128 --num_layers 2 --seq_length 64 --batch_size 32 --num_epochs 1000
</code></pre>
<p>This will train your model and save the model, <strong>in the globals <code>./models</code> folder</strong>, in a format usable in javascript.</p>
<h3><a class="anchor" aria-hidden="true" name="2-run"></a><a href="#2-run" aria-hidden="true" class="hash-link" ><svg aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>2) Run!</h3>
<p>To work with the model in p5ML, you'll just need to point to the new folder in your sketch:</p>
<pre><code class="hljs css javascript"><span class="hljs-keyword">var</span> lstm = <span class="hljs-keyword">new</span> p5ml.LSTMGenerator(<span class="hljs-string">'./models/your_new_model'</span>);
</code></pre>
<p>That's it!</p>
<h2><a class="anchor" aria-hidden="true" name="hyperparameters"></a><a href="#hyperparameters" aria-hidden="true" class="hash-link" ><svg aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Hyperparameters</h2>
<p><em>Thanks to Ross Goodwin!</em></p>
<p>Given the size of the training dataset, you can use:</p>
<ul>
<li>2 MB:
<ul>
<li>rnn_size 256 (or 128)</li>
<li>layers 2</li>
<li>seq_length 64</li>
<li>batch_size 32</li>
<li>dropout 0.25</li>
</ul></li>
<li>5-8 MB:
<ul>
<li>rnn_size 512</li>
<li>layers 2 (or 3)</li>
<li>seq_length 128</li>
<li>batch_size 64</li>
<li>dropout 0.25</li>
</ul></li>
<li>10-20 MB:
<ul>
<li>rnn_size 1024</li>
<li>layers 2 (or 3)</li>
<li>seq_length 128 (or 256)</li>
<li>batch_size 128</li>
<li>dropout 0.25</li>
</ul></li>
<li>25+ MB:
<ul>
<li>rnn_size 2048</li>
<li>layers 2 (or 3)</li>
<li>seq_length 256 (or 128)</li>
<li>batch_size 128</li>
<li>dropout 0.25</li>
</ul></li>
</ul>
<h2><a class="anchor" aria-hidden="true" name="tensorboard"></a><a href="#tensorboard" aria-hidden="true" class="hash-link" ><svg aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Tensorboard</h2>
<p>Tensorflow comes with <a href="https://github.com/tensorflow/tensorboard">Tensorboard</a>: &quot;a suite of web applications for inspecting and understanding your TensorFlow runs and graphs.&quot;.</p>
<p>To visualize training progress, model graphs, and internal state histograms: fire up Tensorboard and point it at your <code>log_dir</code>:</p>
<pre><code class="hljs css bash">$ tensorboard --logdir=./logs/
</code></pre>
<p>Then open a browser to <a href="http://localhost:6006">http://localhost:6006</a> or the correct IP/Port specified.</p>
</span></div></article></div><div class="docs-prevnext"><a class="docs-prev button" href="training-setup.html">← Python Setup</a></div></div></div></div><footer class="nav-footer" id="footer"><section class="sitemap"><div><h5>Docs</h5><a href="/ml5-js/docs/getting-started.html">Getting Started</a><a href="/ml5-js/docs/imagenet.html">API Reference</a><a href="/ml5-js/docs/training-models.html">Training Models</a></div><div><h5>Learning</h5><a href="/ml5-js/docs/tutorials.html">Tutorials</a><a href="/ml5-js/docs/glossary-statistics.html">Glossary</a><a href="/ml5-js/docs/resources.html">Resources</a></div><div><h5>Contribute</h5><a href="/ml5-js/experiments.html">Experiments</a><a href="https://github.com/ITPNYU/ml5-js">Contributing Guide</a><a class="github-button" href="https://github.com/ITPNYU/ml5-js" data-icon="octicon-star" data-count-href="https://github.com/ITPNYU/ml5-js" data-show-count="true" data-count-aria-label="# stargazers on GitHub" aria-label="Star this project on GitHub">Star</a></div></section><a href="https://itp.nyu.edu" target="_blank" class="fbOpenSource"><img src="/ml5-js/img/itp_logo.png" alt="Facebook Open Source" width="60" height="45"/></a><section class="copyright">This project is currently being maintained at NYU ITP by a community of teachers, residents and students.</section></footer></div></body></html>